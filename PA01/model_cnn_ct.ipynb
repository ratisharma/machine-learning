{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l2, l1, l1_l2\n",
    "\n",
    "from keras.layers import Dense, Activation, Flatten, concatenate\n",
    "from keras.layers.local import LocallyConnected1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>geneID1</th>\n",
       "      <th>geneID2</th>\n",
       "      <th>sequence1</th>\n",
       "      <th>sequence2</th>\n",
       "      <th>interaction</th>\n",
       "      <th>Sequence_x</th>\n",
       "      <th>CT_x</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>...</th>\n",
       "      <th>54_y</th>\n",
       "      <th>55_y</th>\n",
       "      <th>56_y</th>\n",
       "      <th>57_y</th>\n",
       "      <th>58_y</th>\n",
       "      <th>59_y</th>\n",
       "      <th>60_y</th>\n",
       "      <th>61_y</th>\n",
       "      <th>62_y</th>\n",
       "      <th>63_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PA1165</td>\n",
       "      <td>PA2424</td>\n",
       "      <td>ATGCGCGCCATGAACGACCGTCTCCCCTCCTTCTGCACCCCGCTGG...</td>\n",
       "      <td>ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...</td>\n",
       "      <td>1</td>\n",
       "      <td>ATGCGCGCCATGAACGACCGTCTCCCCTCCTTCTGCACCCCGCTGG...</td>\n",
       "      <td>[0.03773584905660377, 0.018867924528301886, 0....</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PA4520</td>\n",
       "      <td>PA2424</td>\n",
       "      <td>GTGAAGACCGTACTCTATCCCGCCATCGCGCTGATGAACCGGCTCA...</td>\n",
       "      <td>ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...</td>\n",
       "      <td>0</td>\n",
       "      <td>GTGAAGACCGTACTCTATCCCGCCATCGCGCTGATGAACCGGCTCA...</td>\n",
       "      <td>[0.08080808080808081, 0.10101010101010101, 0.2...</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PA1266</td>\n",
       "      <td>PA2424</td>\n",
       "      <td>ATGAGCGCCGACTACGACCTGCTGATCGTCGGTGCCGGCCCCGCCG...</td>\n",
       "      <td>ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...</td>\n",
       "      <td>0</td>\n",
       "      <td>ATGAGCGCCGACTACGACCTGCTGATCGTCGGTGCCGGCCCCGCCG...</td>\n",
       "      <td>[0.0, 0.0392156862745098, 0.0784313725490196, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PA3585</td>\n",
       "      <td>PA2424</td>\n",
       "      <td>ATGTTCAAGGCGCTGATCGGCGCCGCCGTGGTCGTGCTCCTCGCCG...</td>\n",
       "      <td>ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...</td>\n",
       "      <td>0</td>\n",
       "      <td>ATGTTCAAGGCGCTGATCGGCGCCGCCGTGGTCGTGCTCCTCGCCG...</td>\n",
       "      <td>[0.0, 0.0, 0.2631578947368421, 0.0526315789473...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PA2399</td>\n",
       "      <td>PA2424</td>\n",
       "      <td>GTGCAAGCACTCATAGAGAAGGTGGGCTCCCTTTCCCCCCAGGAAA...</td>\n",
       "      <td>ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...</td>\n",
       "      <td>1</td>\n",
       "      <td>GTGCAAGCACTCATAGAGAAGGTGGGCTCCCTTTCCCCCCAGGAAA...</td>\n",
       "      <td>[0.04559270516717325, 0.060790273556231005, 0....</td>\n",
       "      <td>0.045593</td>\n",
       "      <td>0.060790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 geneID1 geneID2  \\\n",
       "0           0  PA1165  PA2424   \n",
       "1           1  PA4520  PA2424   \n",
       "2           2  PA1266  PA2424   \n",
       "3           3  PA3585  PA2424   \n",
       "4           4  PA2399  PA2424   \n",
       "\n",
       "                                           sequence1  \\\n",
       "0  ATGCGCGCCATGAACGACCGTCTCCCCTCCTTCTGCACCCCGCTGG...   \n",
       "1  GTGAAGACCGTACTCTATCCCGCCATCGCGCTGATGAACCGGCTCA...   \n",
       "2  ATGAGCGCCGACTACGACCTGCTGATCGTCGGTGCCGGCCCCGCCG...   \n",
       "3  ATGTTCAAGGCGCTGATCGGCGCCGCCGTGGTCGTGCTCCTCGCCG...   \n",
       "4  GTGCAAGCACTCATAGAGAAGGTGGGCTCCCTTTCCCCCCAGGAAA...   \n",
       "\n",
       "                                           sequence2  interaction  \\\n",
       "0  ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...            1   \n",
       "1  ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...            0   \n",
       "2  ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...            0   \n",
       "3  ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...            0   \n",
       "4  ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...            1   \n",
       "\n",
       "                                          Sequence_x  \\\n",
       "0  ATGCGCGCCATGAACGACCGTCTCCCCTCCTTCTGCACCCCGCTGG...   \n",
       "1  GTGAAGACCGTACTCTATCCCGCCATCGCGCTGATGAACCGGCTCA...   \n",
       "2  ATGAGCGCCGACTACGACCTGCTGATCGTCGGTGCCGGCCCCGCCG...   \n",
       "3  ATGTTCAAGGCGCTGATCGGCGCCGCCGTGGTCGTGCTCCTCGCCG...   \n",
       "4  GTGCAAGCACTCATAGAGAAGGTGGGCTCCCTTTCCCCCCAGGAAA...   \n",
       "\n",
       "                                                CT_x       0_x       1_x  \\\n",
       "0  [0.03773584905660377, 0.018867924528301886, 0....  0.037736  0.018868   \n",
       "1  [0.08080808080808081, 0.10101010101010101, 0.2...  0.080808  0.101010   \n",
       "2  [0.0, 0.0392156862745098, 0.0784313725490196, ...  0.000000  0.039216   \n",
       "3  [0.0, 0.0, 0.2631578947368421, 0.0526315789473...  0.000000  0.000000   \n",
       "4  [0.04559270516717325, 0.060790273556231005, 0....  0.045593  0.060790   \n",
       "\n",
       "     ...         54_y      55_y      56_y     57_y      58_y      59_y  \\\n",
       "0    ...     0.731259  0.205092  0.647808  0.25884  0.639321  0.998586   \n",
       "1    ...     0.731259  0.205092  0.647808  0.25884  0.639321  0.998586   \n",
       "2    ...     0.731259  0.205092  0.647808  0.25884  0.639321  0.998586   \n",
       "3    ...     0.731259  0.205092  0.647808  0.25884  0.639321  0.998586   \n",
       "4    ...     0.731259  0.205092  0.647808  0.25884  0.639321  0.998586   \n",
       "\n",
       "       60_y      61_y      62_y      63_y  \n",
       "0  0.321075  0.454031  0.770863  0.302687  \n",
       "1  0.321075  0.454031  0.770863  0.302687  \n",
       "2  0.321075  0.454031  0.770863  0.302687  \n",
       "3  0.321075  0.454031  0.770863  0.302687  \n",
       "4  0.321075  0.454031  0.770863  0.302687  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('gene_data_ct.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>54_y</th>\n",
       "      <th>55_y</th>\n",
       "      <th>56_y</th>\n",
       "      <th>57_y</th>\n",
       "      <th>58_y</th>\n",
       "      <th>59_y</th>\n",
       "      <th>60_y</th>\n",
       "      <th>61_y</th>\n",
       "      <th>62_y</th>\n",
       "      <th>63_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.045593</td>\n",
       "      <td>0.060790</td>\n",
       "      <td>0.179331</td>\n",
       "      <td>0.273556</td>\n",
       "      <td>0.072948</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.227964</td>\n",
       "      <td>0.334347</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   interaction       0_x       1_x       2_x       3_x       4_x       5_x  \\\n",
       "0            1  0.037736  0.018868  0.132075  0.150943  0.018868  0.018868   \n",
       "1            0  0.080808  0.101010  0.222222  0.262626  0.070707  0.030303   \n",
       "2            0  0.000000  0.039216  0.078431  0.117647  0.019608  0.009804   \n",
       "3            0  0.000000  0.000000  0.263158  0.052632  0.000000  0.052632   \n",
       "4            1  0.045593  0.060790  0.179331  0.273556  0.072948  0.063830   \n",
       "\n",
       "        6_x       7_x       8_x    ...         54_y      55_y      56_y  \\\n",
       "0  0.132075  0.094340  0.037736    ...     0.731259  0.205092  0.647808   \n",
       "1  0.222222  0.454545  0.272727    ...     0.731259  0.205092  0.647808   \n",
       "2  0.088235  0.068627  0.068627    ...     0.731259  0.205092  0.647808   \n",
       "3  0.105263  0.368421  0.157895    ...     0.731259  0.205092  0.647808   \n",
       "4  0.227964  0.334347  0.127660    ...     0.731259  0.205092  0.647808   \n",
       "\n",
       "      57_y      58_y      59_y      60_y      61_y      62_y      63_y  \n",
       "0  0.25884  0.639321  0.998586  0.321075  0.454031  0.770863  0.302687  \n",
       "1  0.25884  0.639321  0.998586  0.321075  0.454031  0.770863  0.302687  \n",
       "2  0.25884  0.639321  0.998586  0.321075  0.454031  0.770863  0.302687  \n",
       "3  0.25884  0.639321  0.998586  0.321075  0.454031  0.770863  0.302687  \n",
       "4  0.25884  0.639321  0.998586  0.321075  0.454031  0.770863  0.302687  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modeling = df.drop(['Unnamed: 0', 'geneID1', 'geneID2', 'sequence1', 'sequence2','Sequence_x', 'CT_x', 'Sequence_y', 'CT_y'], axis=1)\n",
    "df_modeling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0_x       1_x       2_x       3_x       4_x       5_x       6_x  \\\n",
      "0  0.037736  0.018868  0.132075  0.150943  0.018868  0.018868  0.132075   \n",
      "1  0.080808  0.101010  0.222222  0.262626  0.070707  0.030303  0.222222   \n",
      "2  0.000000  0.039216  0.078431  0.117647  0.019608  0.009804  0.088235   \n",
      "3  0.000000  0.000000  0.263158  0.052632  0.000000  0.052632  0.105263   \n",
      "4  0.045593  0.060790  0.179331  0.273556  0.072948  0.063830  0.227964   \n",
      "\n",
      "        7_x       8_x       9_x    ...         54_y      55_y      56_y  \\\n",
      "0  0.094340  0.037736  0.056604    ...     0.731259  0.205092  0.647808   \n",
      "1  0.454545  0.272727  0.191919    ...     0.731259  0.205092  0.647808   \n",
      "2  0.068627  0.068627  0.009804    ...     0.731259  0.205092  0.647808   \n",
      "3  0.368421  0.157895  0.000000    ...     0.731259  0.205092  0.647808   \n",
      "4  0.334347  0.127660  0.148936    ...     0.731259  0.205092  0.647808   \n",
      "\n",
      "      57_y      58_y      59_y      60_y      61_y      62_y      63_y  \n",
      "0  0.25884  0.639321  0.998586  0.321075  0.454031  0.770863  0.302687  \n",
      "1  0.25884  0.639321  0.998586  0.321075  0.454031  0.770863  0.302687  \n",
      "2  0.25884  0.639321  0.998586  0.321075  0.454031  0.770863  0.302687  \n",
      "3  0.25884  0.639321  0.998586  0.321075  0.454031  0.770863  0.302687  \n",
      "4  0.25884  0.639321  0.998586  0.321075  0.454031  0.770863  0.302687  \n",
      "\n",
      "[5 rows x 128 columns]\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: interaction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df_modeling.drop('interaction', axis=1)\n",
    "y = df_modeling['interaction']\n",
    "print X.head()\n",
    "print y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32430,)\n",
      "(25944, 128)\n",
      "(25944, 2)\n"
     ]
    }
   ],
   "source": [
    "Xmat = X.as_matrix()\n",
    "ym = y.as_matrix()\n",
    "print ym.shape\n",
    "ymat = np.zeros((ym.shape[0],2))\n",
    "ids0 = ym==0\n",
    "ids1 = ym==1\n",
    "ymat[ids0,0] = 1\n",
    "ymat[ids1,1] = 1\n",
    "ymat[:5,:]\n",
    "Xmat_train, Xmat_test, ymat_train, ymat_test = train_test_split(Xmat, ymat, test_size=0.2)\n",
    "print Xmat_train.shape\n",
    "print ymat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0377358490566 0.024045261669\n",
      "0.0808080808081 0.024045261669\n"
     ]
    }
   ],
   "source": [
    "print Xmat[0,0], Xmat[0,64]\n",
    "print Xmat[1,0], Xmat[1,64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_62 (Dense)             (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 2)                 12        \n",
      "=================================================================\n",
      "Total params: 2,857\n",
      "Trainable params: 2,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25944/25944 [==============================] - 2s 93us/step - loss: 0.7366 - acc: 0.6358\n",
      "Epoch 2/100\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.6731 - acc: 0.6700\n",
      "Epoch 3/100\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.6565 - acc: 0.6762\n",
      "Epoch 4/100\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.6475 - acc: 0.6811\n",
      "Epoch 5/100\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.6402 - acc: 0.6865\n",
      "Epoch 6/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.6352 - acc: 0.6868\n",
      "Epoch 7/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.6304 - acc: 0.6901\n",
      "Epoch 8/100\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.6258 - acc: 0.6952\n",
      "Epoch 9/100\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.6227 - acc: 0.6935\n",
      "Epoch 10/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.6182 - acc: 0.6959\n",
      "Epoch 11/100\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.6155 - acc: 0.6988\n",
      "Epoch 12/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.6120 - acc: 0.6990\n",
      "Epoch 13/100\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.6088 - acc: 0.7033\n",
      "Epoch 14/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.6052 - acc: 0.7054\n",
      "Epoch 15/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.6029 - acc: 0.7063\n",
      "Epoch 16/100\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.6004 - acc: 0.7091\n",
      "Epoch 17/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5971 - acc: 0.7136\n",
      "Epoch 18/100\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5955 - acc: 0.7137\n",
      "Epoch 19/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5930 - acc: 0.7144\n",
      "Epoch 20/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5916 - acc: 0.7146\n",
      "Epoch 21/100\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5877 - acc: 0.7171\n",
      "Epoch 22/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5866 - acc: 0.7210\n",
      "Epoch 23/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5847 - acc: 0.7216\n",
      "Epoch 24/100\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5834 - acc: 0.7219\n",
      "Epoch 25/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5817 - acc: 0.7215\n",
      "Epoch 26/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5790 - acc: 0.7230\n",
      "Epoch 27/100\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5769 - acc: 0.7252\n",
      "Epoch 28/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5771 - acc: 0.7244\n",
      "Epoch 29/100\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5746 - acc: 0.7269\n",
      "Epoch 30/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5755 - acc: 0.7283\n",
      "Epoch 31/100\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5732 - acc: 0.7309\n",
      "Epoch 32/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5713 - acc: 0.7332\n",
      "Epoch 33/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5715 - acc: 0.7297\n",
      "Epoch 34/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5700 - acc: 0.7316\n",
      "Epoch 35/100\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5698 - acc: 0.7319\n",
      "Epoch 36/100\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5693 - acc: 0.7317\n",
      "Epoch 37/100\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5673 - acc: 0.7351\n",
      "Epoch 38/100\n",
      "25944/25944 [==============================] - 2s 74us/step - loss: 0.5665 - acc: 0.7337\n",
      "Epoch 39/100\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5673 - acc: 0.7340\n",
      "Epoch 40/100\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5663 - acc: 0.7354\n",
      "Epoch 41/100\n",
      "25944/25944 [==============================] - 2s 75us/step - loss: 0.5649 - acc: 0.7362\n",
      "Epoch 42/100\n",
      "25944/25944 [==============================] - 2s 73us/step - loss: 0.5641 - acc: 0.7356\n",
      "Epoch 43/100\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5637 - acc: 0.7374\n",
      "Epoch 44/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5635 - acc: 0.7393\n",
      "Epoch 45/100\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5638 - acc: 0.7363\n",
      "Epoch 46/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5613 - acc: 0.7387\n",
      "Epoch 47/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5609 - acc: 0.7393\n",
      "Epoch 48/100\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5604 - acc: 0.7386\n",
      "Epoch 49/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5601 - acc: 0.7408\n",
      "Epoch 50/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5591 - acc: 0.7413\n",
      "Epoch 51/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5577 - acc: 0.7388\n",
      "Epoch 52/100\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5567 - acc: 0.7434\n",
      "Epoch 53/100\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5559 - acc: 0.7441\n",
      "Epoch 54/100\n",
      "25944/25944 [==============================] - 2s 71us/step - loss: 0.5566 - acc: 0.7420\n",
      "Epoch 55/100\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.5569 - acc: 0.7429\n",
      "Epoch 56/100\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5555 - acc: 0.7422\n",
      "Epoch 57/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5543 - acc: 0.7442\n",
      "Epoch 58/100\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5541 - acc: 0.7460\n",
      "Epoch 59/100\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5539 - acc: 0.7461\n",
      "Epoch 60/100\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5535 - acc: 0.7455\n",
      "Epoch 61/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5542 - acc: 0.7445\n",
      "Epoch 62/100\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5523 - acc: 0.7466\n",
      "Epoch 63/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5533 - acc: 0.7470\n",
      "Epoch 64/100\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5520 - acc: 0.7479\n",
      "Epoch 65/100\n",
      "25944/25944 [==============================] - 2s 76us/step - loss: 0.5519 - acc: 0.7470\n",
      "Epoch 66/100\n",
      "25944/25944 [==============================] - 1s 52us/step - loss: 0.5513 - acc: 0.7488\n",
      "Epoch 67/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5528 - acc: 0.7465\n",
      "Epoch 68/100\n",
      "25944/25944 [==============================] - 2s 58us/step - loss: 0.5519 - acc: 0.7479\n",
      "Epoch 69/100\n",
      "25944/25944 [==============================] - 2s 59us/step - loss: 0.5514 - acc: 0.7460\n",
      "Epoch 70/100\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5513 - acc: 0.7470\n",
      "Epoch 71/100\n",
      "25944/25944 [==============================] - 2s 59us/step - loss: 0.5514 - acc: 0.7474\n",
      "Epoch 72/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5497 - acc: 0.7483\n",
      "Epoch 73/100\n",
      "25944/25944 [==============================] - 2s 58us/step - loss: 0.5499 - acc: 0.7487\n",
      "Epoch 74/100\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5491 - acc: 0.7515\n",
      "Epoch 75/100\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5504 - acc: 0.7481\n",
      "Epoch 76/100\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.5508 - acc: 0.7494\n",
      "Epoch 77/100\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.5493 - acc: 0.7478\n",
      "Epoch 78/100\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5488 - acc: 0.7509\n",
      "Epoch 79/100\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.5501 - acc: 0.7494\n",
      "Epoch 80/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5489 - acc: 0.7494\n",
      "Epoch 81/100\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.5478 - acc: 0.7483\n",
      "Epoch 82/100\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.5472 - acc: 0.7488\n",
      "Epoch 83/100\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.5462 - acc: 0.7526\n",
      "Epoch 84/100\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5466 - acc: 0.7534\n",
      "Epoch 85/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5473 - acc: 0.7518\n",
      "Epoch 86/100\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.5461 - acc: 0.7507\n",
      "Epoch 87/100\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.5460 - acc: 0.7527\n",
      "Epoch 88/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5471 - acc: 0.7519\n",
      "Epoch 89/100\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5466 - acc: 0.7481\n",
      "Epoch 90/100\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5462 - acc: 0.7525\n",
      "Epoch 91/100\n",
      "25944/25944 [==============================] - 1s 51us/step - loss: 0.5471 - acc: 0.7501\n",
      "Epoch 92/100\n",
      "25944/25944 [==============================] - 2s 59us/step - loss: 0.5465 - acc: 0.7502\n",
      "Epoch 93/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5452 - acc: 0.7518\n",
      "Epoch 94/100\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5479 - acc: 0.7488\n",
      "Epoch 95/100\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5454 - acc: 0.7495\n",
      "Epoch 96/100\n",
      "25944/25944 [==============================] - 2s 72us/step - loss: 0.5448 - acc: 0.7543\n",
      "Epoch 97/100\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5452 - acc: 0.7527\n",
      "Epoch 98/100\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.5448 - acc: 0.7520\n",
      "Epoch 99/100\n",
      "25944/25944 [==============================] - 2s 59us/step - loss: 0.5441 - acc: 0.7511\n",
      "Epoch 100/100\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5441 - acc: 0.7515\n",
      "6486/6486 [==============================] - 0s 73us/step\n",
      "[0.61862406152065907, 0.68802035145284657]\n"
     ]
    }
   ],
   "source": [
    "# The most basic model. input represented as a 128x1 vector;  accuracy=0.8\n",
    "ninput_dim = 128\n",
    "model = Sequential()\n",
    "model.add(Dense(units=20,input_dim=ninput_dim,kernel_regularizer=l1(0.0005), activation='relu'))\n",
    "model.add(Dense(units=10,input_dim=ninput_dim,kernel_regularizer=l1(0.0005), activation='relu'))\n",
    "model.add(Dense(units=5,kernel_regularizer=l1(0.0002),activity_regularizer=l1(0.0001), activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(Xmat_train, ymat_train, epochs=100, batch_size=64)\n",
    "loss_and_metrics = model.evaluate(Xmat_test, ymat_test, batch_size=64)\n",
    "\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               1408      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 5,510\n",
      "Trainable params: 5,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "25944/25944 [==============================] - 2s 85us/step - loss: 0.7192 - acc: 0.6295\n",
      "Epoch 2/150\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.6617 - acc: 0.6661\n",
      "Epoch 3/150\n",
      "25944/25944 [==============================] - 2s 73us/step - loss: 0.6443 - acc: 0.6790\n",
      "Epoch 4/150\n",
      "25944/25944 [==============================] - 2s 77us/step - loss: 0.6331 - acc: 0.6873\n",
      "Epoch 5/150\n",
      "25944/25944 [==============================] - 2s 86us/step - loss: 0.6255 - acc: 0.6922\n",
      "Epoch 6/150\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.6205 - acc: 0.6964\n",
      "Epoch 7/150\n",
      "25944/25944 [==============================] - 2s 75us/step - loss: 0.6152 - acc: 0.6998\n",
      "Epoch 8/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.6109 - acc: 0.7035\n",
      "Epoch 9/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.6073 - acc: 0.7053\n",
      "Epoch 10/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.6054 - acc: 0.7054\n",
      "Epoch 11/150\n",
      "25944/25944 [==============================] - 2s 58us/step - loss: 0.6027 - acc: 0.7091\n",
      "Epoch 12/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.6008 - acc: 0.7101\n",
      "Epoch 13/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5989 - acc: 0.7099\n",
      "Epoch 14/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5958 - acc: 0.7131\n",
      "Epoch 15/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5941 - acc: 0.7130\n",
      "Epoch 16/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5908 - acc: 0.7155\n",
      "Epoch 17/150\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5901 - acc: 0.7158\n",
      "Epoch 18/150\n",
      "25944/25944 [==============================] - 2s 75us/step - loss: 0.5864 - acc: 0.7181\n",
      "Epoch 19/150\n",
      "25944/25944 [==============================] - 2s 72us/step - loss: 0.5846 - acc: 0.7206\n",
      "Epoch 20/150\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5825 - acc: 0.7223\n",
      "Epoch 21/150\n",
      "25944/25944 [==============================] - 2s 72us/step - loss: 0.5820 - acc: 0.7197\n",
      "Epoch 22/150\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5804 - acc: 0.7237\n",
      "Epoch 23/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5788 - acc: 0.7224\n",
      "Epoch 24/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5772 - acc: 0.7243\n",
      "Epoch 25/150\n",
      "25944/25944 [==============================] - 2s 72us/step - loss: 0.5767 - acc: 0.7234\n",
      "Epoch 26/150\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.5744 - acc: 0.7250\n",
      "Epoch 27/150\n",
      "25944/25944 [==============================] - 2s 71us/step - loss: 0.5736 - acc: 0.7260\n",
      "Epoch 28/150\n",
      "25944/25944 [==============================] - 2s 72us/step - loss: 0.5728 - acc: 0.7269\n",
      "Epoch 29/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5709 - acc: 0.7279\n",
      "Epoch 30/150\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.5699 - acc: 0.7303\n",
      "Epoch 31/150\n",
      "25944/25944 [==============================] - 2s 71us/step - loss: 0.5695 - acc: 0.7318\n",
      "Epoch 32/150\n",
      "25944/25944 [==============================] - 2s 73us/step - loss: 0.5669 - acc: 0.7317\n",
      "Epoch 33/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5681 - acc: 0.7317\n",
      "Epoch 34/150\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.5668 - acc: 0.7327\n",
      "Epoch 35/150\n",
      "25944/25944 [==============================] - 2s 73us/step - loss: 0.5662 - acc: 0.7331\n",
      "Epoch 36/150\n",
      "25944/25944 [==============================] - 2s 73us/step - loss: 0.5648 - acc: 0.7354\n",
      "Epoch 37/150\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5642 - acc: 0.7324\n",
      "Epoch 38/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5639 - acc: 0.7341\n",
      "Epoch 39/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5616 - acc: 0.7351\n",
      "Epoch 40/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5615 - acc: 0.7362\n",
      "Epoch 41/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5604 - acc: 0.7354\n",
      "Epoch 42/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5594 - acc: 0.7372\n",
      "Epoch 43/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5610 - acc: 0.7344\n",
      "Epoch 44/150\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.5591 - acc: 0.7378\n",
      "Epoch 45/150\n",
      "25944/25944 [==============================] - 2s 75us/step - loss: 0.5576 - acc: 0.7389\n",
      "Epoch 46/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5565 - acc: 0.7387\n",
      "Epoch 47/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5568 - acc: 0.7394\n",
      "Epoch 48/150\n",
      "25944/25944 [==============================] - 2s 78us/step - loss: 0.5566 - acc: 0.7388\n",
      "Epoch 49/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5553 - acc: 0.7400\n",
      "Epoch 50/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5541 - acc: 0.7405\n",
      "Epoch 51/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5549 - acc: 0.7409\n",
      "Epoch 52/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5546 - acc: 0.7412\n",
      "Epoch 53/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5546 - acc: 0.7381\n",
      "Epoch 54/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5541 - acc: 0.7391\n",
      "Epoch 55/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5523 - acc: 0.7420\n",
      "Epoch 56/150\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5525 - acc: 0.7405\n",
      "Epoch 57/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5516 - acc: 0.7453\n",
      "Epoch 58/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5521 - acc: 0.7436\n",
      "Epoch 59/150\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5514 - acc: 0.7440\n",
      "Epoch 60/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5490 - acc: 0.7459\n",
      "Epoch 61/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5491 - acc: 0.7480\n",
      "Epoch 62/150\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5498 - acc: 0.7438\n",
      "Epoch 63/150\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5472 - acc: 0.7458\n",
      "Epoch 64/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5491 - acc: 0.7455\n",
      "Epoch 65/150\n",
      "25944/25944 [==============================] - 2s 59us/step - loss: 0.5481 - acc: 0.7446\n",
      "Epoch 66/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5465 - acc: 0.7466\n",
      "Epoch 67/150\n",
      "25944/25944 [==============================] - 2s 58us/step - loss: 0.5483 - acc: 0.7440\n",
      "Epoch 68/150\n",
      "25944/25944 [==============================] - 2s 61us/step - loss: 0.5460 - acc: 0.7483\n",
      "Epoch 69/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5459 - acc: 0.7473\n",
      "Epoch 70/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5456 - acc: 0.7463\n",
      "Epoch 71/150\n",
      "25944/25944 [==============================] - 2s 59us/step - loss: 0.5450 - acc: 0.7453\n",
      "Epoch 72/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5456 - acc: 0.7487\n",
      "Epoch 73/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5448 - acc: 0.7490\n",
      "Epoch 74/150\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5440 - acc: 0.7496\n",
      "Epoch 75/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5451 - acc: 0.7523\n",
      "Epoch 76/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5432 - acc: 0.7490\n",
      "Epoch 77/150\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5436 - acc: 0.7502\n",
      "Epoch 78/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5432 - acc: 0.7473\n",
      "Epoch 79/150\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5425 - acc: 0.7488\n",
      "Epoch 80/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5434 - acc: 0.7532\n",
      "Epoch 81/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5415 - acc: 0.7527\n",
      "Epoch 82/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5427 - acc: 0.7508\n",
      "Epoch 83/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5404 - acc: 0.7532\n",
      "Epoch 84/150\n",
      "25944/25944 [==============================] - 1s 58us/step - loss: 0.5405 - acc: 0.7519\n",
      "Epoch 85/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5394 - acc: 0.7563\n",
      "Epoch 86/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5401 - acc: 0.7510\n",
      "Epoch 87/150\n",
      "25944/25944 [==============================] - 2s 77us/step - loss: 0.5406 - acc: 0.7520\n",
      "Epoch 88/150\n",
      "25944/25944 [==============================] - 2s 71us/step - loss: 0.5402 - acc: 0.7539\n",
      "Epoch 89/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5397 - acc: 0.7534\n",
      "Epoch 90/150\n",
      "25944/25944 [==============================] - 1s 57us/step - loss: 0.5387 - acc: 0.7520\n",
      "Epoch 91/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5393 - acc: 0.7546\n",
      "Epoch 92/150\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5385 - acc: 0.7551\n",
      "Epoch 93/150\n",
      "25944/25944 [==============================] - 2s 71us/step - loss: 0.5364 - acc: 0.7574\n",
      "Epoch 94/150\n",
      "25944/25944 [==============================] - 2s 69us/step - loss: 0.5386 - acc: 0.7550\n",
      "Epoch 95/150\n",
      "25944/25944 [==============================] - 2s 83us/step - loss: 0.5373 - acc: 0.7576\n",
      "Epoch 96/150\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5352 - acc: 0.7586\n",
      "Epoch 97/150\n",
      "25944/25944 [==============================] - 2s 73us/step - loss: 0.5360 - acc: 0.7581\n",
      "Epoch 98/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5345 - acc: 0.7591\n",
      "Epoch 99/150\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5366 - acc: 0.7575\n",
      "Epoch 100/150\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.5357 - acc: 0.7598\n",
      "Epoch 101/150\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5334 - acc: 0.7598\n",
      "Epoch 102/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5351 - acc: 0.7571\n",
      "Epoch 103/150\n",
      "25944/25944 [==============================] - 2s 72us/step - loss: 0.5343 - acc: 0.7612\n",
      "Epoch 104/150\n",
      "25944/25944 [==============================] - 1s 55us/step - loss: 0.5338 - acc: 0.7606\n",
      "Epoch 105/150\n",
      "25944/25944 [==============================] - 2s 59us/step - loss: 0.5353 - acc: 0.7574\n",
      "Epoch 106/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5347 - acc: 0.7583\n",
      "Epoch 107/150\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.5318 - acc: 0.7648\n",
      "Epoch 108/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5324 - acc: 0.7645\n",
      "Epoch 109/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5325 - acc: 0.7605\n",
      "Epoch 110/150\n",
      "25944/25944 [==============================] - 1s 58us/step - loss: 0.5317 - acc: 0.7618\n",
      "Epoch 111/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5327 - acc: 0.7601\n",
      "Epoch 112/150\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5318 - acc: 0.7588\n",
      "Epoch 113/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5324 - acc: 0.7618\n",
      "Epoch 114/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5300 - acc: 0.7635\n",
      "Epoch 115/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5322 - acc: 0.7619\n",
      "Epoch 116/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5319 - acc: 0.7631\n",
      "Epoch 117/150\n",
      "25944/25944 [==============================] - 2s 65us/step - loss: 0.5324 - acc: 0.7615\n",
      "Epoch 118/150\n",
      "25944/25944 [==============================] - 1s 56us/step - loss: 0.5297 - acc: 0.7648\n",
      "Epoch 119/150\n",
      "25944/25944 [==============================] - 1s 57us/step - loss: 0.5302 - acc: 0.7624\n",
      "Epoch 120/150\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5299 - acc: 0.7621\n",
      "Epoch 121/150\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.5292 - acc: 0.7632\n",
      "Epoch 122/150\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.5300 - acc: 0.7640\n",
      "Epoch 123/150\n",
      "25944/25944 [==============================] - 2s 70us/step - loss: 0.5290 - acc: 0.7645\n",
      "Epoch 124/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5294 - acc: 0.7655\n",
      "Epoch 125/150\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5292 - acc: 0.7652\n",
      "Epoch 126/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5282 - acc: 0.7666\n",
      "Epoch 127/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5285 - acc: 0.7662\n",
      "Epoch 128/150\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5273 - acc: 0.7676\n",
      "Epoch 129/150\n",
      "25944/25944 [==============================] - 2s 64us/step - loss: 0.5263 - acc: 0.7680\n",
      "Epoch 130/150\n",
      "25944/25944 [==============================] - 2s 81us/step - loss: 0.5267 - acc: 0.7654\n",
      "Epoch 131/150\n",
      "25944/25944 [==============================] - 1s 52us/step - loss: 0.5268 - acc: 0.7673\n",
      "Epoch 132/150\n",
      "25944/25944 [==============================] - 1s 51us/step - loss: 0.5272 - acc: 0.7669\n",
      "Epoch 133/150\n",
      "25944/25944 [==============================] - 1s 52us/step - loss: 0.5255 - acc: 0.7683\n",
      "Epoch 134/150\n",
      "25944/25944 [==============================] - 1s 57us/step - loss: 0.5262 - acc: 0.7673\n",
      "Epoch 135/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5255 - acc: 0.7668\n",
      "Epoch 136/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5245 - acc: 0.7700\n",
      "Epoch 137/150\n",
      "25944/25944 [==============================] - 1s 56us/step - loss: 0.5258 - acc: 0.7699\n",
      "Epoch 138/150\n",
      "25944/25944 [==============================] - 2s 66us/step - loss: 0.5255 - acc: 0.7686\n",
      "Epoch 139/150\n",
      "25944/25944 [==============================] - 1s 55us/step - loss: 0.5251 - acc: 0.7679\n",
      "Epoch 140/150\n",
      "25944/25944 [==============================] - 2s 60us/step - loss: 0.5257 - acc: 0.7698\n",
      "Epoch 141/150\n",
      "25944/25944 [==============================] - 2s 68us/step - loss: 0.5264 - acc: 0.7689\n",
      "Epoch 142/150\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5251 - acc: 0.7702\n",
      "Epoch 143/150\n",
      "25944/25944 [==============================] - 1s 53us/step - loss: 0.5260 - acc: 0.7693\n",
      "Epoch 144/150\n",
      "25944/25944 [==============================] - 2s 67us/step - loss: 0.5248 - acc: 0.7709\n",
      "Epoch 145/150\n",
      "25944/25944 [==============================] - 1s 50us/step - loss: 0.5246 - acc: 0.7711\n",
      "Epoch 146/150\n",
      "25944/25944 [==============================] - 2s 62us/step - loss: 0.5230 - acc: 0.7723\n",
      "Epoch 147/150\n",
      "25944/25944 [==============================] - 1s 56us/step - loss: 0.5251 - acc: 0.7687\n",
      "Epoch 148/150\n",
      "25944/25944 [==============================] - 1s 53us/step - loss: 0.5234 - acc: 0.7709\n",
      "Epoch 149/150\n",
      "25944/25944 [==============================] - 1s 57us/step - loss: 0.5254 - acc: 0.7693\n",
      "Epoch 150/150\n",
      "25944/25944 [==============================] - 2s 63us/step - loss: 0.5231 - acc: 0.7713\n",
      "6486/6486 [==============================] - 0s 59us/step\n",
      "[0.56273144851155832, 0.74337033609016201]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "# # this is the size of our encoded representations\n",
    "# encoding_dim = 20  # 20 floats -> compression of factor 64, assuming the input is 784 floats\n",
    "\n",
    "# # this is our input placeholder\n",
    "# input_X = Input(shape=(128,))\n",
    "# # \"encoded\" is the encoded representation of the input\n",
    "# encoded = Dense(encoding_dim, activation='relu')(input_X)\n",
    "# # \"decoded\" is the lossy reconstruction of the input\n",
    "# decoded = Dense(128, activation='sigmoid')(encoded)\n",
    "\n",
    "# # this model maps an input to its reconstruction\n",
    "# autoencoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "# autoencoder.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "# autoencoder.summary()\n",
    "# autoencoder.fit(Xmat_train, ymat_train, epochs=50, batch_size=64)\n",
    "# loss_and_metrics = model.evaluate(Xmat_test, ymat_test, batch_size=64)\n",
    "aedim = 128\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10,input_dim=aedim,kernel_regularizer=l1(0.0005), activation='relu'))\n",
    "model.add(Dense(units=aedim,kernel_regularizer=l1(0.0002), activation='relu'))\n",
    "model.add(Dense(units=20,kernel_regularizer=l1(0.0002),activity_regularizer=l1(0.0001), activation='relu'))\n",
    "model.add(Dense(units=10,kernel_regularizer=l1(0.0002),activity_regularizer=l1(0.0001), activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(Xmat_train, ymat_train, epochs=150, batch_size=64)\n",
    "loss_and_metrics = model.evaluate(Xmat_test, ymat_test, batch_size=64)\n",
    "\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Convlution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>geneID1</th>\n",
       "      <th>geneID2</th>\n",
       "      <th>sequence1</th>\n",
       "      <th>sequence2</th>\n",
       "      <th>interaction</th>\n",
       "      <th>Sequence_x</th>\n",
       "      <th>CT_x</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>...</th>\n",
       "      <th>54_y</th>\n",
       "      <th>55_y</th>\n",
       "      <th>56_y</th>\n",
       "      <th>57_y</th>\n",
       "      <th>58_y</th>\n",
       "      <th>59_y</th>\n",
       "      <th>60_y</th>\n",
       "      <th>61_y</th>\n",
       "      <th>62_y</th>\n",
       "      <th>63_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PA1165</td>\n",
       "      <td>PA2424</td>\n",
       "      <td>ATGCGCGCCATGAACGACCGTCTCCCCTCCTTCTGCACCCCGCTGG...</td>\n",
       "      <td>ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...</td>\n",
       "      <td>1</td>\n",
       "      <td>ATGCGCGCCATGAACGACCGTCTCCCCTCCTTCTGCACCCCGCTGG...</td>\n",
       "      <td>[0.03773584905660377, 0.018867924528301886, 0....</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PA4520</td>\n",
       "      <td>PA2424</td>\n",
       "      <td>GTGAAGACCGTACTCTATCCCGCCATCGCGCTGATGAACCGGCTCA...</td>\n",
       "      <td>ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...</td>\n",
       "      <td>0</td>\n",
       "      <td>GTGAAGACCGTACTCTATCCCGCCATCGCGCTGATGAACCGGCTCA...</td>\n",
       "      <td>[0.08080808080808081, 0.10101010101010101, 0.2...</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PA1266</td>\n",
       "      <td>PA2424</td>\n",
       "      <td>ATGAGCGCCGACTACGACCTGCTGATCGTCGGTGCCGGCCCCGCCG...</td>\n",
       "      <td>ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...</td>\n",
       "      <td>0</td>\n",
       "      <td>ATGAGCGCCGACTACGACCTGCTGATCGTCGGTGCCGGCCCCGCCG...</td>\n",
       "      <td>[0.0, 0.0392156862745098, 0.0784313725490196, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PA3585</td>\n",
       "      <td>PA2424</td>\n",
       "      <td>ATGTTCAAGGCGCTGATCGGCGCCGCCGTGGTCGTGCTCCTCGCCG...</td>\n",
       "      <td>ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...</td>\n",
       "      <td>0</td>\n",
       "      <td>ATGTTCAAGGCGCTGATCGGCGCCGCCGTGGTCGTGCTCCTCGCCG...</td>\n",
       "      <td>[0.0, 0.0, 0.2631578947368421, 0.0526315789473...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PA2399</td>\n",
       "      <td>PA2424</td>\n",
       "      <td>GTGCAAGCACTCATAGAGAAGGTGGGCTCCCTTTCCCCCCAGGAAA...</td>\n",
       "      <td>ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...</td>\n",
       "      <td>1</td>\n",
       "      <td>GTGCAAGCACTCATAGAGAAGGTGGGCTCCCTTTCCCCCCAGGAAA...</td>\n",
       "      <td>[0.04559270516717325, 0.060790273556231005, 0....</td>\n",
       "      <td>0.045593</td>\n",
       "      <td>0.060790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731259</td>\n",
       "      <td>0.205092</td>\n",
       "      <td>0.647808</td>\n",
       "      <td>0.25884</td>\n",
       "      <td>0.639321</td>\n",
       "      <td>0.998586</td>\n",
       "      <td>0.321075</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.770863</td>\n",
       "      <td>0.302687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 geneID1 geneID2  \\\n",
       "0           0  PA1165  PA2424   \n",
       "1           1  PA4520  PA2424   \n",
       "2           2  PA1266  PA2424   \n",
       "3           3  PA3585  PA2424   \n",
       "4           4  PA2399  PA2424   \n",
       "\n",
       "                                           sequence1  \\\n",
       "0  ATGCGCGCCATGAACGACCGTCTCCCCTCCTTCTGCACCCCGCTGG...   \n",
       "1  GTGAAGACCGTACTCTATCCCGCCATCGCGCTGATGAACCGGCTCA...   \n",
       "2  ATGAGCGCCGACTACGACCTGCTGATCGTCGGTGCCGGCCCCGCCG...   \n",
       "3  ATGTTCAAGGCGCTGATCGGCGCCGCCGTGGTCGTGCTCCTCGCCG...   \n",
       "4  GTGCAAGCACTCATAGAGAAGGTGGGCTCCCTTTCCCCCCAGGAAA...   \n",
       "\n",
       "                                           sequence2  interaction  \\\n",
       "0  ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...            1   \n",
       "1  ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...            0   \n",
       "2  ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...            0   \n",
       "3  ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...            0   \n",
       "4  ATGATGGACGCCTTCGAACTTCCCACCACCCTGGTCCAGGCCCTGC...            1   \n",
       "\n",
       "                                          Sequence_x  \\\n",
       "0  ATGCGCGCCATGAACGACCGTCTCCCCTCCTTCTGCACCCCGCTGG...   \n",
       "1  GTGAAGACCGTACTCTATCCCGCCATCGCGCTGATGAACCGGCTCA...   \n",
       "2  ATGAGCGCCGACTACGACCTGCTGATCGTCGGTGCCGGCCCCGCCG...   \n",
       "3  ATGTTCAAGGCGCTGATCGGCGCCGCCGTGGTCGTGCTCCTCGCCG...   \n",
       "4  GTGCAAGCACTCATAGAGAAGGTGGGCTCCCTTTCCCCCCAGGAAA...   \n",
       "\n",
       "                                                CT_x       0_x       1_x  \\\n",
       "0  [0.03773584905660377, 0.018867924528301886, 0....  0.037736  0.018868   \n",
       "1  [0.08080808080808081, 0.10101010101010101, 0.2...  0.080808  0.101010   \n",
       "2  [0.0, 0.0392156862745098, 0.0784313725490196, ...  0.000000  0.039216   \n",
       "3  [0.0, 0.0, 0.2631578947368421, 0.0526315789473...  0.000000  0.000000   \n",
       "4  [0.04559270516717325, 0.060790273556231005, 0....  0.045593  0.060790   \n",
       "\n",
       "     ...         54_y      55_y      56_y     57_y      58_y      59_y  \\\n",
       "0    ...     0.731259  0.205092  0.647808  0.25884  0.639321  0.998586   \n",
       "1    ...     0.731259  0.205092  0.647808  0.25884  0.639321  0.998586   \n",
       "2    ...     0.731259  0.205092  0.647808  0.25884  0.639321  0.998586   \n",
       "3    ...     0.731259  0.205092  0.647808  0.25884  0.639321  0.998586   \n",
       "4    ...     0.731259  0.205092  0.647808  0.25884  0.639321  0.998586   \n",
       "\n",
       "       60_y      61_y      62_y      63_y  \n",
       "0  0.321075  0.454031  0.770863  0.302687  \n",
       "1  0.321075  0.454031  0.770863  0.302687  \n",
       "2  0.321075  0.454031  0.770863  0.302687  \n",
       "3  0.321075  0.454031  0.770863  0.302687  \n",
       "4  0.321075  0.454031  0.770863  0.302687  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ecoli = pd.read_csv('ecoli_gene_data_ct.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>54_y</th>\n",
       "      <th>55_y</th>\n",
       "      <th>56_y</th>\n",
       "      <th>57_y</th>\n",
       "      <th>58_y</th>\n",
       "      <th>59_y</th>\n",
       "      <th>60_y</th>\n",
       "      <th>61_y</th>\n",
       "      <th>62_y</th>\n",
       "      <th>63_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.365385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.365385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   interaction       0_x       1_x       2_x       3_x       4_x       5_x  \\\n",
       "0            0  1.000000  0.266667  0.600000  0.133333  0.333333  0.733333   \n",
       "1            0  0.384615  0.269231  0.269231  0.769231  0.192308  0.307692   \n",
       "2            0  1.000000  0.444444  0.666667  0.333333  0.333333  0.666667   \n",
       "3            0  1.000000  0.266667  0.600000  0.133333  0.333333  0.733333   \n",
       "4            0  0.630435  0.304348  0.413043  0.673913  0.173913  0.456522   \n",
       "\n",
       "        6_x       7_x       8_x    ...         54_y      55_y      56_y  \\\n",
       "0  0.333333  0.200000  0.266667    ...     0.448276  0.000000  0.068966   \n",
       "1  0.307692  0.346154  0.115385    ...     0.448276  0.000000  0.068966   \n",
       "2  0.555556  0.444444  0.111111    ...     0.448276  0.000000  0.068966   \n",
       "3  0.333333  0.200000  0.266667    ...     0.480769  0.153846  0.519231   \n",
       "4  0.478261  0.304348  0.304348    ...     0.480769  0.153846  0.519231   \n",
       "\n",
       "       57_y      58_y      59_y      60_y      61_y      62_y      63_y  \n",
       "0  0.344828  0.000000  0.241379  0.310345  0.206897  0.034483  0.172414  \n",
       "1  0.344828  0.000000  0.241379  0.310345  0.206897  0.034483  0.172414  \n",
       "2  0.344828  0.000000  0.241379  0.310345  0.206897  0.034483  0.172414  \n",
       "3  0.269231  0.846154  0.750000  0.307692  0.173077  0.653846  0.365385  \n",
       "4  0.269231  0.846154  0.750000  0.307692  0.173077  0.653846  0.365385  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modeling_ecoli = df_ecoli.drop(['Unnamed: 0', 'geneID1', 'geneID2', 'sequence1', 'sequence2','Seq_x', 'CT_x', 'Seq_y', 'CT_y'], axis=1)\n",
    "df_modeling_ecoli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0_x       1_x       2_x       3_x       4_x       5_x       6_x  \\\n",
      "0  1.000000  0.266667  0.600000  0.133333  0.333333  0.733333  0.333333   \n",
      "1  0.384615  0.269231  0.269231  0.769231  0.192308  0.307692  0.307692   \n",
      "2  1.000000  0.444444  0.666667  0.333333  0.333333  0.666667  0.555556   \n",
      "3  1.000000  0.266667  0.600000  0.133333  0.333333  0.733333  0.333333   \n",
      "4  0.630435  0.304348  0.413043  0.673913  0.173913  0.456522  0.478261   \n",
      "\n",
      "        7_x       8_x       9_x    ...         54_y      55_y      56_y  \\\n",
      "0  0.200000  0.266667  0.266667    ...     0.448276  0.000000  0.068966   \n",
      "1  0.346154  0.115385  0.192308    ...     0.448276  0.000000  0.068966   \n",
      "2  0.444444  0.111111  0.222222    ...     0.448276  0.000000  0.068966   \n",
      "3  0.200000  0.266667  0.266667    ...     0.480769  0.153846  0.519231   \n",
      "4  0.304348  0.304348  0.065217    ...     0.480769  0.153846  0.519231   \n",
      "\n",
      "       57_y      58_y      59_y      60_y      61_y      62_y      63_y  \n",
      "0  0.344828  0.000000  0.241379  0.310345  0.206897  0.034483  0.172414  \n",
      "1  0.344828  0.000000  0.241379  0.310345  0.206897  0.034483  0.172414  \n",
      "2  0.344828  0.000000  0.241379  0.310345  0.206897  0.034483  0.172414  \n",
      "3  0.269231  0.846154  0.750000  0.307692  0.173077  0.653846  0.365385  \n",
      "4  0.269231  0.846154  0.750000  0.307692  0.173077  0.653846  0.365385  \n",
      "\n",
      "[5 rows x 128 columns]\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: interaction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_ecoli = df_modeling_ecoli.drop('interaction', axis=1)\n",
    "y_ecoli = df_modeling_ecoli['interaction']\n",
    "print X_ecoli.head()\n",
    "print y_ecoli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21591,)\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "(17272, 128)\n",
      "(17272, 2)\n"
     ]
    }
   ],
   "source": [
    "Xmat_ecoli = X_ecoli.as_matrix()\n",
    "ym_ecoli = y_ecoli.as_matrix()\n",
    "print ym_ecoli.shape\n",
    "ymat_ecoli = np.zeros((ym_ecoli.shape[0],2))\n",
    "ids0 = ym_ecoli==0\n",
    "ids1 = ym_ecoli==1\n",
    "ymat_ecoli[ids0,0] = 1\n",
    "ymat_ecoli[ids1,1] = 1\n",
    "print ymat_ecoli[:5,:]\n",
    "Xmat_train_ecoli, Xmat_test_ecoli, ymat_train_ecoli, ymat_test_ecoli = train_test_split(Xmat_ecoli, ymat_ecoli, test_size=0.2)\n",
    "print Xmat_train_ecoli.shape\n",
    "print ymat_train_ecoli.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 20)                2580      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 2,812\n",
      "Trainable params: 2,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "17272/17272 [==============================] - 1s 35us/step - loss: 0.7809 - acc: 0.5861\n",
      "Epoch 2/50\n",
      "17272/17272 [==============================] - 1s 29us/step - loss: 0.7188 - acc: 0.6270\n",
      "Epoch 3/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6974 - acc: 0.6375\n",
      "Epoch 4/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6857 - acc: 0.6430\n",
      "Epoch 5/50\n",
      "17272/17272 [==============================] - 0s 26us/step - loss: 0.6780 - acc: 0.6459\n",
      "Epoch 6/50\n",
      "17272/17272 [==============================] - 0s 25us/step - loss: 0.6720 - acc: 0.6487\n",
      "Epoch 7/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6663 - acc: 0.6555\n",
      "Epoch 8/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6618 - acc: 0.6587\n",
      "Epoch 9/50\n",
      "17272/17272 [==============================] - 0s 26us/step - loss: 0.6590 - acc: 0.6565\n",
      "Epoch 10/50\n",
      "17272/17272 [==============================] - 0s 26us/step - loss: 0.6551 - acc: 0.6605\n",
      "Epoch 11/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6527 - acc: 0.6621\n",
      "Epoch 12/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6493 - acc: 0.6664\n",
      "Epoch 13/50\n",
      "17272/17272 [==============================] - 1s 30us/step - loss: 0.6469 - acc: 0.6647\n",
      "Epoch 14/50\n",
      "17272/17272 [==============================] - 0s 29us/step - loss: 0.6445 - acc: 0.6669\n",
      "Epoch 15/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6430 - acc: 0.6662\n",
      "Epoch 16/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6411 - acc: 0.6692\n",
      "Epoch 17/50\n",
      "17272/17272 [==============================] - 0s 28us/step - loss: 0.6395 - acc: 0.6692\n",
      "Epoch 18/50\n",
      "17272/17272 [==============================] - 0s 28us/step - loss: 0.6371 - acc: 0.6764\n",
      "Epoch 19/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6352 - acc: 0.6740\n",
      "Epoch 20/50\n",
      "17272/17272 [==============================] - 1s 30us/step - loss: 0.6347 - acc: 0.6797\n",
      "Epoch 21/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6332 - acc: 0.6746\n",
      "Epoch 22/50\n",
      "17272/17272 [==============================] - 1s 29us/step - loss: 0.6321 - acc: 0.6782\n",
      "Epoch 23/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6296 - acc: 0.6793\n",
      "Epoch 24/50\n",
      "17272/17272 [==============================] - 0s 25us/step - loss: 0.6283 - acc: 0.6811\n",
      "Epoch 25/50\n",
      "17272/17272 [==============================] - 0s 28us/step - loss: 0.6255 - acc: 0.6859\n",
      "Epoch 26/50\n",
      "17272/17272 [==============================] - 0s 29us/step - loss: 0.6248 - acc: 0.6865\n",
      "Epoch 27/50\n",
      "17272/17272 [==============================] - 1s 32us/step - loss: 0.6236 - acc: 0.6864\n",
      "Epoch 28/50\n",
      "17272/17272 [==============================] - 1s 30us/step - loss: 0.6224 - acc: 0.6859\n",
      "Epoch 29/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6220 - acc: 0.6856\n",
      "Epoch 30/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6210 - acc: 0.6865\n",
      "Epoch 31/50\n",
      "17272/17272 [==============================] - 1s 34us/step - loss: 0.6210 - acc: 0.6865\n",
      "Epoch 32/50\n",
      "17272/17272 [==============================] - 0s 28us/step - loss: 0.6191 - acc: 0.6894\n",
      "Epoch 33/50\n",
      "17272/17272 [==============================] - 1s 33us/step - loss: 0.6188 - acc: 0.6903\n",
      "Epoch 34/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6162 - acc: 0.6910\n",
      "Epoch 35/50\n",
      "17272/17272 [==============================] - 0s 26us/step - loss: 0.6157 - acc: 0.6911\n",
      "Epoch 36/50\n",
      "17272/17272 [==============================] - 0s 26us/step - loss: 0.6138 - acc: 0.6925\n",
      "Epoch 37/50\n",
      "17272/17272 [==============================] - 1s 34us/step - loss: 0.6134 - acc: 0.6913\n",
      "Epoch 38/50\n",
      "17272/17272 [==============================] - 1s 32us/step - loss: 0.6136 - acc: 0.6913\n",
      "Epoch 39/50\n",
      "17272/17272 [==============================] - 1s 32us/step - loss: 0.6117 - acc: 0.6954\n",
      "Epoch 40/50\n",
      "17272/17272 [==============================] - 0s 28us/step - loss: 0.6121 - acc: 0.6930\n",
      "Epoch 41/50\n",
      "17272/17272 [==============================] - 0s 29us/step - loss: 0.6116 - acc: 0.6941\n",
      "Epoch 42/50\n",
      "17272/17272 [==============================] - 1s 29us/step - loss: 0.6105 - acc: 0.6955\n",
      "Epoch 43/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6113 - acc: 0.6965\n",
      "Epoch 44/50\n",
      "17272/17272 [==============================] - 0s 23us/step - loss: 0.6089 - acc: 0.6966\n",
      "Epoch 45/50\n",
      "17272/17272 [==============================] - 0s 26us/step - loss: 0.6080 - acc: 0.6980\n",
      "Epoch 46/50\n",
      "17272/17272 [==============================] - 0s 26us/step - loss: 0.6074 - acc: 0.6975\n",
      "Epoch 47/50\n",
      "17272/17272 [==============================] - 0s 26us/step - loss: 0.6071 - acc: 0.6977\n",
      "Epoch 48/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6052 - acc: 0.7023\n",
      "Epoch 49/50\n",
      "17272/17272 [==============================] - 0s 28us/step - loss: 0.6052 - acc: 0.7003\n",
      "Epoch 50/50\n",
      "17272/17272 [==============================] - 0s 27us/step - loss: 0.6059 - acc: 0.7020\n",
      "4319/4319 [==============================] - 0s 33us/step\n",
      "[0.60560337479784132, 0.70363510015193553]\n"
     ]
    }
   ],
   "source": [
    "# The most basic model. input represented as a 180x1 vector;  accuracy=0.8\n",
    "ninput_dim = 128\n",
    "model = Sequential()\n",
    "model.add(Dense(units=20,input_dim=ninput_dim,kernel_regularizer=l1(0.0005), activation='relu'))\n",
    "model.add(Dense(units=10,kernel_regularizer=l1(0.0002),activity_regularizer=l1(0.0001), activation='relu'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(Xmat_train_ecoli, ymat_train_ecoli, epochs=50, batch_size=128)\n",
    "loss_and_metrics = model.evaluate(Xmat_test_ecoli, ymat_test_ecoli, batch_size=128)\n",
    "\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name AutoEncoder",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ca7ff66c4579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from keras.layers import Containers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name AutoEncoder"
     ]
    }
   ],
   "source": [
    "# from keras.layers import Containers\n",
    "from keras.layers import Dense, AutoEncoder\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "ae = Sequential()\n",
    "encoder = Sequential([Dense(20), Dense(20)])\n",
    "decoder = Sequential([Dense(20), Dense(20)])\n",
    "ae.add(AutoEncoder(encoder=encoder, decoder=decoder,\n",
    "                   output_reconstruction=True, tie_weights=True))\n",
    "\n",
    "ae.compile(loss='mean_squared_error', optimizer=RMSprop())\n",
    "ae.fit(Xmat_train_ecoli, Xmat_train_ecoli, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "       show_accuracy=False, verbose=1, validation_data=[Xmat_test_ecoli, Xmat_test_ecoli])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
